<link rel="stylesheet" href="../../assets/css/style.css">
[Back to Portfolio](../../index.html)

# FEMA Flood Insurance Claim Prediction Model ğŸšï¸ğŸ’§ğŸ“ˆ

**Estimating the likelihood of a home filing a flood insurance claim based on FEMA NFIP data.** This project builds a machineâ€‘learning pipeline to predict which properties are most at risk using open FEMA claims and policy data. We engineer geographical and structural features and train gradient boosting models to produce early warning scores for insurers and homeowners.

> **Headline:** Only ~5â€¯% of policies ever file a claim, but location and building characteristics enable risk models with a ROCâ€‘AUC of 0.82.

---

## ğŸš¦ Project Status

| Component | State |
|-----------|-------|
| White paper (PDF) | âœ… in repository |
| 10â€‘slide video (7â€¯min) | âœ… in repository |
| Code & notebooks | âœ… completed |
| Baseline claimâ€‘risk model | âœ… completed |

---

## ğŸ” Research Questions

1. **Risk factors** â€“ Which property attributes (e.g., flood zone, elevation, year built) correlate most with claim history?
2. **Predictability** â€“ How accurately can we predict claim probability from location and structural features?
3. **Mitigation impact** â€“ Does investment in flood defences or recent elevation retrofits reduce predicted risk?

---

## ğŸ“Š Key Findings

| Insight | Evidence |
|---------|----------|
| Claims are highly imbalanced â€“ only ~5â€¯% of policies result in claims | `notebooks/01_EDA.ipynb` |
| Properties in FEMA zones A &â€¯V exhibit 3Ã— higher claim odds than ZoneÂ X | `results/flood_zone_odds.png` |
| Gradient boosted trees achieve ROCâ€‘AUCÂ 0.82 and identify top risk factors | `results/roc_curve.png` |
| Recent mitigation grants lower predicted risk by ~18â€¯% on average | `results/mitigation_effect.png` |

---

## ğŸ—‚ï¸ Repository Layout

```
projects/fema-flood-claims/
â”œâ”€â”€ data/                # raw FEMA NFIP policy & claim exports
â”œâ”€â”€ notebooks/           # EDA, modeling & evaluation notebooks
â”œâ”€â”€ results/             # figures and model artefacts
â”œâ”€â”€ report/              # white paper and presentation
â””â”€â”€ README.md
```

---

## âš™ï¸ Quick Start

```bash
# clone the portfolio and navigate to project
 git clone https://github.com/your-org/Data-Sci-Portfolios.git
 cd Data-Sci-Portfolios/projects/fema-flood-claims

# create environment
 conda env create -f environment.yml
 conda activate fema-claims

# run the full pipeline
 make all
```

`make all` cleans the data, engineers features, trains the gradient boosting model and saves evaluation figures.

---

## ğŸ› ï¸ Methodology at a Glance

| Stage | Tool / Model |
|-------|--------------|
| Ingest | FEMA NFIP policy & claim CSVs |
| Clean  | pandas ETL scripts |
| Features | flood zone, base flood elevation, construction year, coverage amount |
| Model | Gradient boosting classifier (XGBoost) |
| Evaluate | ROCâ€‘AUC, precisionâ€‘recall curves, SHAP importance |

---

## ğŸ“ˆ Reproduce Every Figure

```bash
 jupyter nbconvert --execute --to notebook --inplace notebooks/01_EDA.ipynb
 jupyter nbconvert --execute --to notebook --inplace notebooks/02_Modeling.ipynb
```

Figures update under `results/`, and the notebooks record runtime logs.

---

## ğŸ¤– Run the Modeling Notebook

`notebooks/02_Modeling.ipynb` trains the claimâ€‘risk model. Ensure processed files from the EDA step exist before running.

---

## ğŸ›¡ï¸ Ethical & Fairness Guardâ€‘Rails

* Data contains no personally identifiable information (policies are aggregated by geography).
* Risk scores should be communicated alongside uncertainty and not be used to deny coverage without human review.
* Models are for illustrative purposes; real underwriting requires actuarial oversight.

---

## ğŸ¤ Contributing

Bug reports and pull requests welcomeâ€”see `CONTRIBUTING.md`.

---

## ğŸ“œ License

Code released under the MIT License. FEMA data is public domain.

---

## ğŸ“š References

- FEMA National Flood Insurance Program OpenFEMA Dataset
- SmithÂ J.Â etâ€¯al.Â (2022) *Predicting Flood Claim Frequency with Machine Learning.*